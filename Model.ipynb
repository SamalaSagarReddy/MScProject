{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2IdXrpwCoxS"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "SzOlOEaB3SF_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "kdZkMjWKymbl",
    "outputId": "70d43341-7acb-4155-f9ec-da89d81d16b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>979502</th>\n",
       "      <td>It will keep a strong-willed Beagle in her place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918541</th>\n",
       "      <td>Barbie Fairytopia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829265</th>\n",
       "      <td>A Must Have</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633450</th>\n",
       "      <td>Rawk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646816</th>\n",
       "      <td>earphone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  target\n",
       "979502  It will keep a strong-willed Beagle in her place.       1\n",
       "918541                                  Barbie Fairytopia       1\n",
       "829265                                        A Must Have       1\n",
       "633450                                               Rawk       1\n",
       "646816                                           earphone       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn .csv files into pandas DataFrame's\n",
    "train_df = pd.read_csv('C:/Users/DIVYA/Desktop/Movie_review/train_modified.csv')\n",
    "train_df = train_df[train_df['text'].notnull()]\n",
    "train_df = train_df.sample(frac=0.1)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "weUGMJ90W1C1",
    "outputId": "1c093f14-dc0d-467a-a850-5a8efdebe8d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264216</th>\n",
       "      <td>Dangerous and not for kids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384419</th>\n",
       "      <td>Very Disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160605</th>\n",
       "      <td>Good supplemental reading, but rely on the PMBOK!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227944</th>\n",
       "      <td>Bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243803</th>\n",
       "      <td>Beginners Woodcarving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "264216                         Dangerous and not for kids\n",
       "384419                                  Very Disappointed\n",
       "160605  Good supplemental reading, but rely on the PMBOK!\n",
       "227944                                              Bored\n",
       "243803                              Beginners Woodcarving"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('C:/Users/DIVYA/Desktop/Movie_review/test_modified.csv')\n",
    "test_df = test_df[test_df['text'].notnull()]\n",
    "test_df = test_df.sample(frac=0.1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8SAWC3IX0upd",
    "outputId": "416a17e3-b001-4284-e76e-6aabe0843b1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>819939</th>\n",
       "      <td>Please describe the content!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258431</th>\n",
       "      <td>The Metaphysical Foundations of Logic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451583</th>\n",
       "      <td>Confused</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548303</th>\n",
       "      <td>best \"natural\" moisturizer around</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925950</th>\n",
       "      <td>...about crazy birds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  target\n",
       "819939           Please describe the content!       0\n",
       "258431  The Metaphysical Foundations of Logic       1\n",
       "451583                               Confused       0\n",
       "548303      best \"natural\" moisturizer around       1\n",
       "925950                   ...about crazy birds       1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) # shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9XRTG9el7oQ"
   },
   "source": [
    "### Below code is used to find the count of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-u4jQ9t502O1",
    "outputId": "6345a88d-da19-468a-a65b-c36b26cd28c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    53011\n",
       "0    51844\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class?\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGjDCKH7aCQw"
   },
   "source": [
    "Since we have two target values, we're dealing with a binary classification problem.\n",
    "\n",
    "It's fairly balanced too, about 50% negative class (target = 0) and 50% positive class (target = 1).\n",
    "\n",
    "Where,\n",
    "\n",
    "1 = Positive Review\n",
    "0 = Negative Review\n",
    "And what about the total number of samples we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN2KbwLkacFm"
   },
   "source": [
    "### Total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vxeXCxtCURWN",
    "outputId": "3f3fc5f0-4d8e-4fb3-f2e6-c1d91a7352f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 104855\n",
      "Total test samples: 39999\n",
      "Total samples: 144854\n"
     ]
    }
   ],
   "source": [
    "# How many samples total?\n",
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-Cg0jVeaipV"
   },
   "source": [
    "### Visualise the 10 random training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKxKxLOJ3Xhh",
    "outputId": "76a7c3dd-c21a-44a1-b9d1-3aa56435f3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (Positive Review)\n",
      "Text:\n",
      "Excelleent\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (Negative Review)\n",
      "Text:\n",
      "hunk of gunk\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (Negative Review)\n",
      "Text:\n",
      "spongbob NOT\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (Negative Review)\n",
      "Text:\n",
      "its awful\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (Negative Review)\n",
      "Text:\n",
      "The film is rudderless\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training examples\n",
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(Positive Review)\" if target > 0 else \"(Negative Review)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hlgr7Pa9aoV-"
   },
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "maxNRGLrndJV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use train_test_split to split training data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
    "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
    "                                                                            test_size=0.1, # dedicate 10% of samples to validation set\n",
    "                                                                            random_state=42) # random state for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Too bad I can't rate 0 stars\", 'A Green Tea with Flavor',\n",
       "       'Wrong fit for my truck', ...,\n",
       "       'People really believe this stuff, kinda scary',\n",
       "       'Oftern imitated never Duplicated',\n",
       "       \"1984? I don't think so. Brave New World is weak.\"], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['so bad', 'Propolis soothes', 'A Truely Original Band', ...,\n",
       "       'Still my favorite tale', 'Not just another CD',\n",
       "       'For Simpsons fans.'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrHUd4dXbUlU",
    "outputId": "9ca1f50e-50eb-4ea7-bd9f-96480eefd7f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94369, 94369, 10486, 10486)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASYr5zCCbc39",
    "outputId": "84c9d1a7-e8b7-498b-fb2a-4da1102d30fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Brave', 'Nice water heater', 'its a BUST',\n",
       "        'The plot was funny and the cast did a great job of drawing y',\n",
       "        'Also positive', 'Exciting', 'Arguably worse than \"Plan 9\"',\n",
       "        \"This band, like an STD, just doesn't seem to go away..\",\n",
       "        'An underground classic', 'Put me out of my misery.....'],\n",
       "       dtype=object),\n",
       " array([1, 1, 0, 1, 1, 1, 0, 0, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 10 training sentences and their labels\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8g6_urIa2If"
   },
   "source": [
    "## Converting text into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDfwCv5Aa5QO"
   },
   "source": [
    "### Text vectorization (tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9IyudtB9p6z4"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "# Note: in TensorFlow 2.6+, you no longer need \"layers.experimental.preprocessing\"\n",
    "# you can use: \"tf.keras.layers.TextVectorization\", see https://github.com/tensorflow/tensorflow/releases/tag/v2.6.0 for more\n",
    "\n",
    "# Use the default TextVectorization variables\n",
    "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
    "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
    "                                    split=\"whitespace\", # how to split tokens\n",
    "                                    ngrams=None, # create groups of n-words?\n",
    "                                    output_mode=\"int\", # how to map tokens to numbers\n",
    "                                    output_sequence_length=None) # how long should the output sequence of tokens be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kp3vcRO0qJq5",
    "outputId": "d735c10c-bc9c-438d-db8d-db6d0f9bc0f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average number of tokens (words) in training reviews\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Tg_7lGCSqbWb"
   },
   "outputs": [],
   "source": [
    "# Setup text vectorization with custom variables\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15 # max length our sequences will be (e.g. how many words from a review does our model see?)\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode=\"int\",\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc9mvxNWW5tl"
   },
   "source": [
    "Commented below because it is taking 10 mins to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "eZXARxrrw70x"
   },
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Wh9XjEXZw-_D"
   },
   "outputs": [],
   "source": [
    "# # Create sample sentence and tokenize it\n",
    "# sample_sentence = \"There's a flood in my street!\"\n",
    "# text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BcNnqfFTxBTM"
   },
   "outputs": [],
   "source": [
    "# # Choose a random sentence from the training dataset and tokenize it\n",
    "# random_sentence = random.choice(train_sentences)\n",
    "# print(f\"Original text:\\n{random_sentence}\\\n",
    "#       \\n\\nVectorized version:\")\n",
    "# text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uDnlZYnDxEwR"
   },
   "outputs": [],
   "source": [
    "# # Get the unique words in the vocabulary\n",
    "# words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "# top_5_words = words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
    "# bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
    "# print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
    "# print(f\"Top 5 most common words: {top_5_words}\") \n",
    "# print(f\"Bottom 5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pnSiHIZG8BHI"
   },
   "source": [
    "### Creating an Embedding using an Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwjEtoA38CJm",
    "outputId": "d0203637-354d-4e74-ae4d-022d936a0341"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x2034b4fa188>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
    "                             output_dim=128, # set size of embedding vector\n",
    "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
    "                             input_length=max_length, # how long is each input\n",
    "                             name=\"embedding_1\") \n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4uHMRE5N8Jbe"
   },
   "outputs": [],
   "source": [
    "# # Get a random sentence from training set\n",
    "# random_sentence = random.choice(train_sentences)\n",
    "# print(f\"Original text:\\n{random_sentence}\\\n",
    "#       \\n\\nEmbedded version:\")\n",
    "\n",
    "# # Embed the random sentence (turn it into numerical representation)\n",
    "# sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "# sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "5Fq88IwG8PA7"
   },
   "outputs": [],
   "source": [
    "# # Check out a single token's embedding\n",
    "# sample_embed[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLGRVhvtXZil"
   },
   "source": [
    "## Model 0: Naive Bayes with TF-IDF Encoder (baseline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaKrkb5_8PZj",
    "outputId": "2f53d9b8-1a5f-4090-ac99-badc4d5cddd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "model_0.fit(train_sentences, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcZfcESCXiOB",
    "outputId": "7a8eefe0-f443-449a-c582-72967a5cc544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 80.26%\n"
     ]
    }
   ],
   "source": [
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baEcqEILXirU",
    "outputId": "3b5869d9-572d-4475-9729-d482dacb5594"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dK4-m85YZ0j"
   },
   "source": [
    "### Creating an evaluation function for our model experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "  \"\"\"\n",
    "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "\n",
    "  Args:\n",
    "  -----\n",
    "  y_true = true labels in the form of a 1D array\n",
    "  y_pred = predicted labels in the form of a 1D array\n",
    "\n",
    "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
    "  \"\"\"\n",
    "  # Calculate model accuracy\n",
    "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
    "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "  model_results = {\"accuracy\": model_accuracy,\n",
    "                  \"precision\": model_precision,\n",
    "                  \"recall\": model_recall,\n",
    "                  \"f1\": model_f1}\n",
    "  return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 80.25939347701697,\n",
       " 'precision': 0.8026476329527267,\n",
       " 'recall': 0.8025939347701697,\n",
       " 'f1': 0.8025506294699017}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "baseline_results = calculate_results(y_true=val_labels,\n",
    "                                     y_pred=baseline_preds)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_0.pkl', 'wb') as fid:\n",
    "    pickle.dump(model_0, fid,2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dataframe \n",
    "cat = test_df\n",
    "index_dict = dict(zip(cat.columns,range(cat.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cat', 'wb') as fid:\n",
    "    pickle.dump(index_dict, fid,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "j2IdXrpwCoxS",
    "M9XRTG9el7oQ",
    "rN2KbwLkacFm",
    "5-Cg0jVeaipV",
    "Hlgr7Pa9aoV-",
    "R8g6_urIa2If",
    "aDfwCv5Aa5QO",
    "pnSiHIZG8BHI",
    "iLGRVhvtXZil",
    "1dK4-m85YZ0j",
    "NLSCWElkYexm",
    "eplYB1tjLwjA",
    "muuzNQLS4U6-",
    "MA8JP7Ub4qSV"
   ],
   "name": "MSc Project_main_code.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
